---
title: "Homework 2"
author: Rio Yan
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

```{r}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na("month") %>% 
  mutate(year = 2018) %>% 
  relocate(year)


precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na("month") %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

precip_df = 
  left_join(precip_df, month_df, by = "month")

```


This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. 

The median number of sports balls found in a dumpter in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`. 
The median number of sports balls found in a dumpter in 2018 was `r trashwheel_df %>% filter(year == 2018) %>% pull(sports_balls) %>% median()`.
The total preciptitation in 2017 was `r precip_df %>% filter(year == 2017) %>% pull(total) %>% sum()` inches.
The total preciptitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.



## Problem 2

Read the NYC subway station dataset.

```{r}
nycsubway_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names()
```


Select and covert entry variable from character to logical. change vending to make it easier for the proportion question.
```{r}
nycsubway_df_clean = 
  select(nycsubway_df, line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE),
         vending = recode(vending, "YES" = TRUE, "NO" = FALSE)
         )
```


This dataset contains information on the NYC transit data. The dataset contains information related to each subways stations in NYC, including their names, latitude and longitude, routes, each entrance and exit, and vending.

For now, I loaded the data from the data file and clean the variable names. I then dropped the not as useful data variables and converted entry and vending variables from character variables to logical variables. 

After cleaning, there are a total of `r nrow(nycsubway_df_clean)` rows and `r ncol(nycsubway_df_clean)` columns in our cleaned dataset. The data right now is still not so tidy.


#### Answer questions about dataset:

How many distinct stations are there?

```{r}
nycsubway_df_clean_distinct = 
  distinct(nycsubway_df_clean, line, station_name, .keep_all = TRUE) 
```
##### There are `r nrow(nycsubway_df_clean_distinct)` distinct stations.


How many stations are ADA compliant?

```{r}
count(filter(nycsubway_df_clean_distinct, ada == "TRUE"))
count(filter(nycsubway_df_clean, ada == "TRUE"))
```
##### There are `r count(filter(nycsubway_df_clean_distinct, ada == "TRUE"))` stations in the distinct station dataframe that are ADA compliant. There are `r count(filter(nycsubway_df_clean, ada == "TRUE"))` stations in the origianl dataframe that are ADA compliant.


What proportion of station entrances / exits without vending allow entrance?

```{r}
# the number of stations entrances / exits that do not have vending
no_vending = count(filter(nycsubway_df_clean, vending == "FALSE"))
      
# the number of stations entrances / exits that allow entrance but do not have vending
entry_no_vending = count(filter(nycsubway_df_clean, vending == "FALSE" & entry == "TRUE"))

percentage = entry_no_vending / no_vending
```
##### The proportion is `r percentage`


Reformat route number and route name to be distinct variables.
First convert route8-11 from num to character variables

```{r}
nycsubway_df_clean_route = 
  nycsubway_df_clean %>% 
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)
         )
       
nycsubway_tidy_data = 
  pivot_longer(
    nycsubway_df_clean_route,
    route1:route11,
    names_to = "route_number",
    values_to = "route_name"
    )
```

How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

```{r}
distinct_a =
  filter(nycsubway_tidy_data, route_name == "A") %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  count()
  
distinct_a_ada = 
  filter(nycsubway_tidy_data, route_name == "A") %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  filter(ada == "TRUE") %>% 
  count()

a_ada =
  filter(nycsubway_tidy_data, route_name == "A") %>% 
  filter(ada == "TRUE") %>% 
  count()
```
##### There are `r distinct_a` distinct stations that serve A train. There are `r distinct_a_ada` distinct stations serve A train and are ADA compliant. Additionally, there are `r a_ada` (not distinct) stations serve A train and are ADA compliant.


## Problem 3

Load and clean data in pols-month.csv

```{r}
pols_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
   mutate(year = as.integer(year),
          month = as.integer(month),
          day = as.integer(day)
          )

pols_month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

pols_df = 
  left_join(pols_df, pols_month_df, by = "month") %>% 
  mutate(
    month = month_name) %>% 
  select(year:rep_dem)
```

Create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

```{r}
pols_df = 
  mutate(pols_df, president = 
           case_when(
             prez_dem == 1 ~ "dem",
             prez_gop == 1 ~ "gop")) %>% 
         select(-day, -prez_dem, -prez_gop)
```

Load and clean data in snp.csv. 

```{r}
snp_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year")) %>%
   mutate(month = as.integer(month),
          day = as.integer(day),
          year = as.integer(year)) %>% 
  arrange(year, month) %>% 
  relocate(year, month) %>% 
  left_join(pols_month_df, by = "month") %>% 
  mutate(month = month_name) %>% 
  select(year:close, -day)
```


Tidy the unemployment data so that it can be merged with the previous datasets.

```{r}
unemploy_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>%
  select(year, January = jan, February = feb, March = mar, April = apr, May = may, June = jun, July = jul, August = aug, September = sep, October = oct, November = nov, December = dec) %>% 
  pivot_longer(
    January:December,
    names_to = "month",
    values_to = "unemploy_percent") %>% 
  mutate(month = as.character(month),
         year = as.integer(year))
```

Join the three datasets.

```{r}
final_data = 
  left_join(pols_df, snp_df, by = c("year", "month")) %>% 
  left_join(unemploy_df, by = c("year", "month"))

str(final_data)
```

Description: 

There are three datasets combined in the final dataset: pols_df, snp_df, and unemploy_df. 
The first file “pols-month” contains 822 observations of 9 variables originally related to the number of national politicians who are democratic or republican at any given time. After cleaning the data, the cleaned pols_df has `r nrow(pols_df)` rows and `r ncol(pols_df)` columns. Important variables in the dataset include year, month, president, and number of different parties representatives on the associated dates. President variable indicates whether the president was democratic or republican. The year range in pols_df ranges from 1947 to 2015. The year range is the largest among all three data, so when merging the datasets, 1947 - 1948 have some NA values. 

The second snp.csv data sets contains 787 observations of 2 variables related to Standard & Poor’s stock market index (S&P), often used as a representative measure of stock market as a whole. After cleaning, the cleaned snp_df has `r nrow(snp_df)` rows and `r ncol(snp_df)` columns because I separated the date variable into year and month. The close variable represents the closing values of the S&P stock index on the associated date.The range of the year starts from 1950 to 2015. 

The third unemployment dataset contains 68 observations of 13 variables, containing year and month variables to document percentage of unemployment on the associated dates. After cleaning, the cleaned unemploy_df contains `r nrow(unemploy_df)` rows and `r ncol(unemploy_df)` columns because I combined all months variables into one variable "month" using pivot_longer while putting the unemployment percentages into the "unemployment" column. The year ranges from 1948 to 2015. 

The final_df is created by joining all three datasets by year and month. The final_df contains`r nrow(final_data)` rows and `r ncol(final_data)` columns, retaining useful variables from the three small datasets such as date, the number of parties representatives and indication of president's party, the closing values of the S&P stock index, and percentage of unemployment. The year ranges from 1947 to 2015. 



