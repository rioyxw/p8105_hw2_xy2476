Homework 2
================
Rio Yan

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na("month") %>% 
  mutate(year = 2018) %>% 
  relocate(year)


precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na("month") %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

precip_df = 
  left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

The median number of sports balls found in a dumpter in 2017 was 8. The
median number of sports balls found in a dumpter in 2018 was 4. The
total preciptitation in 2017 was 32.93 inches. The total preciptitation
in 2018 was 70.33 inches.

## Problem 2

Read the NYC subway station dataset.

``` r
nycsubway_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

Select and covert entry variable from character to logical.

``` r
nycsubway_df_clean = 
  select(nycsubway_df, line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE),
         vending = recode(vending, "YES" = TRUE, "NO" = FALSE)
         )
```

This dataset contains information on the NYC transit data. The dataset
contains information related to each subways stations in NYC, including
their names, latitude and longitude, routes, each entrance and exit, and
vending.

For now, I loaded the data from the data file and clean the variable
names. I then dropped the not as useful data variables and converted
entry and vending variables from character variables to logical
variables.

After cleaning, there are a total of 1868 rows and 19 columns in our
cleaned dataset. The data right now is still not so tidy.

#### Answer questions about dataset:

How many distinct stations are there?

``` r
nycsubway_df_clean_distinct = 
  distinct(nycsubway_df_clean, line, station_name, .keep_all = TRUE) 
```

##### There are 465 distinct stations.

How many stations are ADA compliant?

``` r
count(filter(nycsubway_df_clean_distinct, ada == "TRUE"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    84

##### There are 84 distinct stations.

What proportion of station entrances / exits without vending allow
entrance?

``` r
# the number of stations entrances / exits that do not have vending
no_vending = count(filter(nycsubway_df_clean, vending == "FALSE"))
      
# the number of stations entrances / exits that allow entrance but do not have vending
entry_no_vending = count(filter(nycsubway_df_clean, vending == "FALSE" & entry == "TRUE"))

percentage = entry_no_vending / no_vending
```

##### The proportion is 0.3770492

\#Reformat route number and route name to be distinct variables. \#First
convert route8-11 from num to character variables. which dataset do we
use? distinct or no

``` r
nycsubway_df_clean_route = 
  nycsubway_df_clean_distinct %>% 
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)
         )
       
nycsubway_tidy_data = 
  pivot_longer(
    nycsubway_df_clean_route,
    route1:route11,
    names_to = "route_number",
    values_to = "route_name"
    )
```

How many distinct stations serve the A train? Of the stations that serve
the A train, how many are ADA compliant?

``` r
count(filter(nycsubway_tidy_data, route_name == "A"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    60

``` r
count(filter(nycsubway_tidy_data, route_name == "A" & ada == "TRUE"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    17

##### There are 60 served A train. There are 17 stations served A train and are ADA compliant.

## Problem 3

Load and clean data in pols-month.csv

``` r
pols_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
   mutate(year = as.integer(year),
          month = as.integer(month),
          day = as.integer(day)
          )
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

pols_df = 
  left_join(pols_df, pols_month_df, by = "month") %>% 
  mutate(
    month = month_name) %>% 
  select(year:rep_dem)
```

Create a president variable taking values gop and dem, and remove
prez\_dem and prez\_gop; and remove the day variable.

``` r
pols_df = 
  mutate(pols_df, president = 
           case_when(
             prez_dem == 1 ~ "dem",
             prez_gop == 1 ~ "gop")) %>% 
         select(-day, -prez_dem, -prez_gop)
```

Load and clean data in snp.csv.

``` r
snp_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year")) %>%
   mutate(month = as.integer(month),
          day = as.integer(day),
          year = as.integer(year)) %>% 
  arrange(year, month) %>% 
  relocate(year, month) %>% 
  left_join(pols_month_df, by = "month") %>% 
  mutate(month = month_name) %>% 
  select(year:close, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

\#\#do we need to drop day????

Tidy the unemployment data so that it can be merged with the previous
datasets.

``` r
unemploy_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>%
  select(year, January = jan, February = feb, March = mar, April = apr, May = may, June = jun, July = jul, August = aug, September = sep, October = oct, November = nov, December = dec) %>% 
  pivot_longer(
    January:December,
    names_to = "month",
    values_to = "unemploy_percent") %>% 
  mutate(month = as.character(month),
         year = as.integer(year))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Join the three datasets.

``` r
final_data = 
  left_join(pols_df, snp_df, by = c("year", "month")) %>% 
  left_join(unemploy_df, by = c("year", "month"))

str(final_data)
```

    ## tibble [822 × 11] (S3: tbl_df/tbl/data.frame)
    ##  $ year            : int [1:822] 1947 1947 1947 1947 1947 1947 1947 1947 1947 1947 ...
    ##  $ month           : chr [1:822] "January" "February" "March" "April" ...
    ##  $ gov_gop         : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop         : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop         : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem         : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem         : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem         : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president       : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ close           : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemploy_percent: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

There are three datasets combined in the final dataset: pols\_df,
snp\_df, and unemploy\_df. The first file “pols-month” contains 822
observations of 9 variables originally related to the number of national
politicians who are democratic or republican at any given time. After
cleaning the data, the cleaned pols\_df has 822 rows and 9 columns.
Important variables in the dataset include year, month, president, and
number of different parties representatives on the associated dates.
President variable indicates whether the president was democratic or
republican. The year range in pols\_df ranges from 1947 to 2015. The
year range is the largest among all three data, so when merging the
datasets, 1947 - 1948 have some NA values.

The second snp.csv data sets contains 787 observations of 2 variables
related to Standard & Poor’s stock market index (S\&P), often used as a
representative measure of stock market as a whole. After cleaning, the
cleaned snp\_df has 787 rows and 3 columns because I separated the date
variable into year and month. The close variable represents the closing
values of the S\&P stock index on the associated date.The range of the
year starts from 1950 to 2015.

The third unemployment dataset contains 68 observations of 13 variables,
containing year and month variables to document percentage of
unemployment on the associated dates. After cleaning, the cleaned
unemploy\_df contains 816 rows and 3 columns because I combined all
months variables into one variable “month” using pivot\_longer while
putting the unemployment percentages into the “unemployment” column. The
year ranges from 1948 to 2015.

The final\_df is created by joining all three datasets by year and
month. The final\_df contains822 rows and 11 columns, retaining useful
variables from the three small datasets such as date, the number of
parties representatives and indication of president’s party, the closing
values of the S\&P stock index, and percentage of unemployment. The year
ranges from 1947 to 2015.
