Homework 2
================
Rio Yan

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na("month") %>% 
  mutate(year = 2018) %>% 
  relocate(year)


precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na("month") %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

precip_df = 
  left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

The median number of sports balls found in a dumpter in 2017 was 8. The
median number of sports balls found in a dumpter in 2018 was 4. The
total preciptitation in 2017 was 32.93 inches. The total preciptitation
in 2018 was 70.33 inches.

## Problem 2

Read the NYC subway station dataset.

``` r
nycsubway_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

Select and covert entry variable from character to logical.

``` r
nycsubway_df_clean = 
  select(nycsubway_df, line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE),
         vending = recode(vending, "YES" = TRUE, "NO" = FALSE)
         )
```

This dataset contains information on the NYC transit data. The dataset
contains information related to each subways stations in NYC, including
their names, latitude and longitude, routes, each entrance and exit.

For now, I imported the data from the data file and clean the variable
names. I then drop the not as useful data variables and convert entry
and vending variables from character variable to logical variable.

After cleaning, there are a total of 1868 rows and 19 columns in our
final dataset. The data right now is still not so tidy.

How many distinct stations are there?

``` r
nycsubway_df_clean_distinct = 
  distinct(nycsubway_df_clean, line, station_name, .keep_all = TRUE) 
```

There are 465 distinct stations.

How many stations are ADA compliant?

``` r
count(filter(nycsubway_df_clean_distinct, ada == "TRUE"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    84

What proportion of station entrances / exits without vending allow
entrance? This question is asking that among all the stations entrances
/ exits which do not have vending, what proportion allow entrance. To be
more clear, you will need to firstly calculate the number of stations
entrances / exits that do not have vending. Then, calculate the number
of stations entrances / exits that allow entrance but do not have
vending.0.3874

``` r
count(filter(nycsubway_df_clean_distinct, vending == "FALSE"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1     9

``` r
# the number of stations entrances / exits that allow entrance but do not have vending
count(filter(nycsubway_df_clean_distinct, vending == "FALSE" & entry == "TRUE"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1     5

``` r
count(filter(nycsubway_df_clean_distinct, vending == "FALSE" & entry == "TRUE"))/count(filter(nycsubway_df_clean_distinct, vending == "FALSE"))
```

    ##           n
    ## 1 0.5555556

``` r
count(filter(nycsubway_df_clean_distinct, vending == "FALSE"))/count(filter(nycsubway_df_clean_distinct, vending == "FALSE" & entry == "TRUE"))
```

    ##     n
    ## 1 1.8

Reformat route number and route name to be distinct variables. First
convert route8-11 from num to character variables.

``` r
nycsubway_df_clean_route = 
  nycsubway_df_clean_distinct %>% 
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)
         )
       
nycsubway_tidy_data = 
  pivot_longer(
    nycsubway_df_clean_route,
    route1:route11,
    names_to = "route_number",
    values_to = "route_name"
    )
```

How many distinct stations serve the A train? Of the stations that serve
the A train, how many are ADA compliant?

``` r
count(filter(nycsubway_tidy_data, route_name == "A"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    60

``` r
count(filter(nycsubway_tidy_data, route_name == "A" & ada == "TRUE"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    17

## Problem 3

Load and clean data in pols-month.csv Use separate() to break up the
variable mon into integer variables year, month, and day; replace month
number with month name; create a president variable taking values gop
and dem, and remove prez\_dem and prez\_gop; and remove the day
variable.

``` r
pols_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
   mutate(year = as.integer(year),
          month = as.integer(month),
          day = as.integer(day)
          )
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

pols_df = 
  left_join(pols_df, pols_month_df, by = "month") %>% 
  mutate(
    month = month_name) %>% 
  select(year:rep_dem)
```

create a president variable taking values gop and dem, and remove
prez\_dem and prez\_gop; and remove the day variable.

``` r
pols_df = 
  mutate(pols_df, president = 
           case_when(
             prez_dem == 1 ~ "dem",
             prez_gop == 1 ~ "gop")) %>% 
         select(-day, -prez_dem, -prez_gop)
```

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year")) %>%
   mutate(month = as.integer(month),
          day = as.integer(day),
          year = as.integer(year)
          ) %>% 
  arrange(year, month) %>% 
  relocate(year, month) %>% 
  left_join(pols_month_df, by = "month") %>% 
  mutate(month = month_name) %>% 
  select(year:close, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

do we need to drop day????

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemploy_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>%
  select(year, january = jan, february = feb, march = mar, april = apr, may = may, june = jun, july = jul, august = aug, september = sep, october = oct, november = nov, december = dec) %>% 
  pivot_longer(
    january:december,
    names_to = "month",
    values_to = "unemploy_percent") %>% 
  mutate(month = as.character(month),
         year = as.integer(year))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
str(pols_df)
```

    ## tibble [822 × 9] (S3: tbl_df/tbl/data.frame)
    ##  $ year     : int [1:822] 1947 1947 1947 1947 1947 1947 1947 1947 1947 1947 ...
    ##  $ month    : chr [1:822] "January" "February" "March" "April" ...
    ##  $ gov_gop  : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop  : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop  : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem  : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem  : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem  : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president: chr [1:822] "dem" "dem" "dem" "dem" ...

``` r
str(snp_df)
```

    ## tibble [787 × 3] (S3: tbl_df/tbl/data.frame)
    ##  $ year : int [1:787] 1950 1950 1950 1950 1950 1950 1950 1950 1950 1950 ...
    ##  $ month: chr [1:787] "January" "February" "March" "April" ...
    ##  $ close: num [1:787] 17 17.2 17.3 18 18.8 ...

Join the three datasets.

``` r
final_data = 
  left_join(pols_df, snp_df) %>% 
  left_join(unemploy_df)
```

    ## Joining, by = c("year", "month")
    ## Joining, by = c("year", "month")
